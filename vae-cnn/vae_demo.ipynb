{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vae import VAE\n",
    "from functools import reduce\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LunarLander Training Data\n",
    "Go ahead and load the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunar_data_path = 'LunarLander-v2_img_10_200.npz'\n",
    "lunar_data = np.load(lunar_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the model itself, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "outputExpanded": false,
    "outputHidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lunar_vae_32 = VAE()\n",
    "lunar_vae_32.make_vae(lunar_data_path, 32)\n",
    "lunar_vae_32.load_model('LunarLander_32.h5')\n",
    "\n",
    "lunar_vae_64 = VAE()\n",
    "lunar_vae_64.make_vae(lunar_data_path, 64)\n",
    "lunar_vae_64.load_model('LunarLander_64.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LunarLander Visualization\n",
    "Here's what a typical frame from this environment will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = lunar_data['arr_0'][5]\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "fig.add_subplot(111).imshow(img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE managed to capture all of the above in just one latent vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = lunar_vae_32.encode_image(np.array([img0]))\n",
    "z0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side-by-side comparison of original data & VAE reconstruction, for your viewing pleasure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec0 = lunar_vae_32.decode_latent(z0)[0]\n",
    "f, axarr = plt.subplots(1,2,figsize=(12,12))\n",
    "axarr[0].imshow(img0)\n",
    "axarr[1].imshow(rec0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about just how compressed the information is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "compression = reduce(operator.mul, (rec0.shape[i] for i in range(len(rec0.shape)))) / z0.shape[1]\n",
    "print(str(compression) + \"x compression ratio!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not exactly the same (some noise), but VAE reconstruction gets the gist of it!\n",
    "\n",
    "### VAE Resiliency\n",
    "Now, what happens if we add some encoding noise?\n",
    "\n",
    "Let's nudge our latent vector a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 += 5 * 1.2\n",
    "rec0 = lunar_vae_32.decode_latent(z0)[0]\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "fig.add_subplot(111).imshow(rec0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's introduce a spaceship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = lunar_data['arr_8'][30]\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "fig.add_subplot(111).imshow(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our new latent vector look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "z1 = lunar_vae_32.encode_image(np.array([img1]))\n",
    "z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = lunar_vae_32.decode_latent(z1)[0]\n",
    "f, axarr = plt.subplots(1,2,figsize=(12,12))\n",
    "axarr[0].imshow(img1)\n",
    "axarr[1].imshow(rec1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrain looks good (maybe a bit fuzzy?), but where's the spaceship?!\n",
    "\n",
    "A lot of reconstruction loss is going associated with the black/white since they are the extremes. The purple is not a huge deal, being pretty close to black anyway. It is in the net's interest to get the terrain right first, so it will dedicate most of 32-dim latent vector to that.\n",
    "\n",
    "Let's try a bigger latent vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = lunar_vae_64.encode_image(np.array([img1]))\n",
    "z1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = lunar_vae_64.decode_latent(z1)[0]\n",
    "f, axarr = plt.subplots(1,2,figsize=(12,12))\n",
    "axarr[0].imshow(img1)\n",
    "axarr[1].imshow(rec1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrain looks crisper, and there's definitely a discernible spaceship now (exact ship details don't really matter). Looks good!\n",
    "\n",
    "However: does it generalize to other environments?\n",
    "\n",
    "## Space Invaders VAE\n",
    "\n",
    "Let's try out the model with Space Invaders-v0. We're gonna go ahead and load the data & model from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_data_path = 'SpaceInvaders-v0_img_10_250.npz'\n",
    "space_data = np.load(space_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "space_vae = VAE()\n",
    "space_vae.make_vae(space_data_path, 64)\n",
    "space_vae.load_model('SpaceInvaders_64.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a typical data frame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "img2 = space_data['arr_0'][0]\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "fig.add_subplot(111).imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the latent encoding of the above frame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = space_vae.encode_image(np.array([img2]))\n",
    "z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a side-by-side comparison with the original & reconstruction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = space_vae.decode_latent(z2)[0]\n",
    "f, axarr = plt.subplots(1,2,figsize=(12, 12))\n",
    "axarr[0].imshow(img2)\n",
    "axarr[1].imshow(rec2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty damn good. Some slight fuzziness if you squint, but very, very good reconstruction accuracy overall!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for on in [-1, -28, -46]:\n",
    "  img2 = space_data['arr_5'][on] #also do 8\n",
    "  z2 = space_vae.encode_image(np.array([img2]))\n",
    "  rec2 = space_vae.decode_latent(z2)[0]\n",
    "  f, axarr = plt.subplots(1,2,figsize=(8,8))\n",
    "  axarr[0].imshow(img2)\n",
    "  axarr[1].imshow(rec2)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all elements there (and in the right color too)!\n",
    "\n",
    "Exactly how small can we make these latent vectors?\n",
    "\n",
    "## CartPole VAE\n",
    "\n",
    "Obviously our overall method is way too overpowered for CartPole, but it's a good way to see just how well our VAE can learn features. \n",
    "\n",
    "Let's go ahead and load the model & data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_data_path = 'CartPole-v0_img_10_50.npz'\n",
    "cart_data = np.load(cart_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "outputHidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cart_vae = VAE()\n",
    "cart_vae.make_vae(cart_data_path, 8)\n",
    "cart_vae.load_model('CartPole_8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a typical frame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cart_data['arr_0'][-28] #(0, 0), (0, -5), (1, 15)\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about a typical latent encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3 = cart_vae.encode_image(np.array([img3]))\n",
    "z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 8 dimensions, that's right. Theoretically, we could get down to as little as 2, but it would require copious training time.\n",
    "\n",
    "Let's go ahead and do a side-by-side original & reconstruction comparison!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec3 = cart_vae.decode_latent(z3)[0]\n",
    "f, axarr = plt.subplots(1,2,figsize=(8,8))\n",
    "axarr[0].imshow(img3)\n",
    "axarr[1].imshow(rec3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good to me!"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "nteract": {
   "version": "0.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
